---
title: "Chunk Tier Verification"
subtitle: "Evaluating positive identification and negative pool quality"
execute:
  cache: false
---

## Overview

This notebook verifies the known act identification system that supports C1 (Measure ID) codebook development. The system classifies document chunks (50-page sliding windows) from US government documents into three tiers:

- **Tier 1**: Verbatim passage matches from `aligned_data` (gold standard)
- **Tier 2**: Act name matches via whitespace-normalized substring, subcomponent decomposition, or co-occurrence rules
- **Negative**: All remaining chunks, tagged with continuous `key_density` metric

We evaluate coverage, matching mechanisms, temporal consistency, and negative pool quality to ensure the tier system provides a robust foundation for LOOCV evaluation in Stage 2.

The identification of *known* acts is only implemented in the US, as it is the only country for which we know the acts from @romer2010.

### Corpus year filter

The evaluation corpus is filtered to documents published through **2007** (`max_doc_year = 2007`). @romer2010 was published in 2010, with the last identified act signed in 2003 (Jobs and Growth Tax Relief Reconciliation Act). Documents through approximately 2007 represent the universe R&R had access to when conducting their analysis. Post-2007 documents can only contribute retrospective mentions of these acts, which would inflate Tier 2 recall beyond what the actual identification task requires. Setting `max_doc_year = NULL` restores the full 1946-2022 corpus for sensitivity analysis.

```{r}
#| label: setup
#| cache: false

pacman::p_load(targets, tidyverse, gt, patchwork, here)

here::i_am("notebooks/verify_chunk_tiers.qmd")
tar_config_set(store = here("_targets"))
source(here("R/gt_theme.R"))
set_theme(theme_minimal())
```

```{r}
#| label: load-data

aligned_data <- tar_read(aligned_data)
c1_chunk_data <- tar_read(c1_chunk_data)
diagnostics <- tar_read(c1_tier_diagnostics)
```

## Tier Distribution

```{r}
#| label: tbl-tier-distribution
#| tbl-cap: "Distribution of chunks across three tiers"

c1_chunk_data$summary %>%
  gt() %>%
  cols_label(
    category = "Tier",
    n_chunks = "Count",
    pct = "Percentage"
  ) %>%
  fmt_number(columns = n_chunks, decimals = 0) %>%
  fmt_number(columns = pct, decimals = 1, pattern = "{x}%") %>%
  gt_theme_report()
```

The tier system identifies `r scales::comma(c1_chunk_data$summary$n_chunks[1])` Tier 1 chunks (verbatim passage matches) and `r scales::comma(c1_chunk_data$summary$n_chunks[2])` Tier 2 chunks (act name matches). The negative pool comprises `r sprintf("%.1f%%", c1_chunk_data$summary$pct[3])` of all chunks, providing substantial diversity for hard-negative sampling in C1 evaluation.

## Coverage Check

```{r}
#| label: tbl-coverage
#| tbl-cap: "Act coverage across tiers"

tier1_acts <- unique(c1_chunk_data$tier1$act_name)
tier2_acts <- unique(c1_chunk_data$tier2$act_name)
all_acts <- aligned_data$act_name

coverage <- tibble(act_name = all_acts) %>%
  mutate(
    has_tier1 = act_name %in% tier1_acts,
    has_tier2 = act_name %in% tier2_acts,
    has_any = has_tier1 | has_tier2,
    status = case_when(
      has_tier1 & has_tier2 ~ "Both tiers",
      has_tier1 ~ "Tier 1 only",
      has_tier2 ~ "Tier 2 only",
      TRUE ~ "UNCOVERED"
    )
  )

# Summary table
coverage %>%
  count(status, name = "n_acts") %>%
  mutate(pct = n_acts / sum(n_acts) * 100) %>%
  gt() %>%
  cols_label(
    status = "Coverage Status",
    n_acts = "Acts",
    pct = "Percentage"
  ) %>%
  fmt_number(columns = n_acts, decimals = 0) %>%
  fmt_number(columns = pct, decimals = 1, pattern = "{x}%") %>%
  tab_style(
    style = cell_fill(color = "#ffcccc"),
    locations = cells_body(rows = status == "UNCOVERED")
  ) %>%
  gt_theme_report()
```

```{r}
#| label: coverage-check-logic

uncovered_acts <- coverage %>% filter(!has_any)
n_uncovered <- nrow(uncovered_acts)
```

**Coverage Status**: `r if(n_uncovered == 0) "PASS" else paste0("FAIL - ", n_uncovered, " uncovered acts")`

All 44 acts should have at least one tier match. `r if(n_uncovered > 0) paste0("Uncovered acts: ", paste(uncovered_acts$act_name, collapse = "; ")) else "All acts successfully matched."`

## Per-Act Chunk Matches

```{r}
#| label: tbl-per-act-matches
#| tbl-cap: "Chunk matches per act across tiers"

tier1_counts <- c1_chunk_data$tier1 %>% count(act_name, name = "tier1_n")
tier2_counts <- c1_chunk_data$tier2 %>% count(act_name, name = "tier2_n")

per_act <- tibble(act_name = aligned_data$act_name) %>%
  left_join(tier1_counts, by = "act_name") %>%
  left_join(tier2_counts, by = "act_name") %>%
  replace_na(list(tier1_n = 0, tier2_n = 0)) %>%
  mutate(total = tier1_n + tier2_n) %>%
  arrange(desc(total))

per_act %>%
  gt() %>%
  cols_label(
    act_name = "Act Name",
    tier1_n = "Tier 1",
    tier2_n = "Tier 2",
    total = "Total"
  ) %>%
  fmt_number(columns = c(tier1_n, tier2_n, total), decimals = 0) %>%
  tab_style(
    style = cell_fill(color = "#ffcccc"),
    locations = cells_body(rows = total == 0)
  ) %>%
  gt_theme_report()
```

Acts with zero matches indicate either: (1) no relevant passages in `aligned_data`, or (2) matching logic failures. High Tier 2 counts relative to Tier 1 suggest extensive discussion beyond labeled passages, which is expected for major legislation.

```{r}
#| label: fig-corpus-vs-matches
#| fig-cap: "Corpus chunk density (bars, left axis) and total chunk matches per act (points, right axis) by year"
#| fig-width: 10
#| fig-height: 5

per_act_year <- per_act %>%
  left_join(aligned_data %>% select(act_name, year), by = "act_name")

corpus_counts <- diagnostics$corpus_year_counts
scale_factor <- max(corpus_counts$n) / max(per_act_year$total)

ggplot() +
  geom_col(data = corpus_counts, aes(x = year, y = n),
           fill = "steelblue", alpha = 0.35) +
  geom_point(data = per_act_year,
             aes(x = year, y = total * scale_factor, color = tier1_n > 0),
             size = 2.5,
             position = position_jitter(width = 0.3, seed = 42)) +
  scale_y_continuous(
    name = "Chunks in Corpus",
    sec.axis = sec_axis(~ . / scale_factor, name = "Chunk Matches per Act")
  ) +
  scale_color_manual(
    values = c("TRUE" = "#4CAF50", "FALSE" = "#FF9800"),
    labels = c("TRUE" = "Has Tier 1", "FALSE" = "Tier 2 only"),
    name = NULL
  ) +
  labs(x = "Year") +
  theme(legend.position = "bottom")
```

The bars show corpus density over time (filtered to documents through 2007); the points overlay each act at its signed year with match count on the right axis. Green points have at least one verbatim Tier 1 match; orange points rely entirely on Tier 2 name matching. Acts in sparse corpus years tend to have fewer matches.

## Matching Mechanism Breakdown

```{r}
#| label: mechanism-analysis

mechanism_tbl <- diagnostics$mechanism_tbl
```

```{r}
#| label: tbl-mechanism-detail
#| tbl-cap: "Search terms and match counts by mechanism for each act"

mechanism_tbl %>%
  arrange(act_name, desc(n_matches)) %>%
  gt() %>%
  cols_label(
    act_name = "Act",
    year = "Year",
    mechanism = "Mechanism",
    search_term = "Search Term",
    n_matches = "Matches"
  ) %>%
  fmt_number(columns = n_matches, decimals = 0) %>%
  tab_style(
    style = cell_fill(color = "#e8f5e9"),
    locations = cells_body(rows = n_matches > 0)
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffebee"),
    locations = cells_body(rows = n_matches == 0)
  ) %>%
  gt_theme_report()
```

```{r}
#| label: tbl-mechanism-summary
#| tbl-cap: "Summary of matching mechanisms per act"

mechanism_summary <- mechanism_tbl %>%
  group_by(act_name, year, mechanism) %>%
  summarize(n_matches = sum(n_matches), .groups = "drop") %>%
  pivot_wider(
    names_from = mechanism,
    values_from = n_matches,
    values_fill = 0
  )

# Compute union-based total (not sum, since mechanisms can overlap)
totals <- mechanism_tbl %>%
  filter(n_matches > 0) %>%
  distinct(act_name) %>%
  left_join(
    per_act %>% select(act_name, total),
    by = "act_name"
  )

mechanism_summary <- mechanism_summary %>%
  left_join(totals, by = "act_name") %>%
  arrange(desc(total))

mechanism_summary %>%
  gt() %>%
  cols_label(act_name = "Act", year = "Year") %>%
  sub_missing(missing_text = "\u2014") %>%
  tab_style(
    style = cell_fill(color = "#ffebee"),
    locations = cells_body(columns = total, rows = !is.na(total) & total == 0)
  ) %>%
  gt_theme_report()
```

Subcomponent decomposition provides redundancy across multiple mechanisms (full name, split-on-"and", parenthetical extraction, embedded formal names, Public Law numbers). Co-occurrence rules target acts with generic names that require multi-term matching. Acts with zero total matches require investigation.

## Temporal Consistency

```{r}
#| label: timing-analysis

timing_df <- diagnostics$timing_df
```

```{r}
#| label: fig-temporal-all
#| fig-cap: "Document year distribution of Tier 2 matches per act (red line = signed year)"
#| fig-height: 14
#| fig-width: 12
#| column: page

ggplot(timing_df, aes(x = chunk_year)) +
  geom_histogram(binwidth = 1, fill = "steelblue", alpha = 0.7) +
  geom_vline(aes(xintercept = signed_year), color = "red", linetype = "dashed", linewidth = 0.5) +
  facet_wrap(~label, ncol = 4, scales = "free_y") +
  labs(
    x = "Document Year",
    y = "Chunks"
  ) 
  # theme(
  #   strip.text = element_text(size = 7),
  #   axis.text.x = element_text(size = 6, angle = 45, hjust = 1),
  #   axis.text.y = element_text(size = 6)
  # )
```

The red dashed line marks the act's signed year. Acts should show peak discussion around signing, with trailing references in subsequent years. Off-peak distributions suggest either: (1) anticipatory discussion (budget proposals), (2) retrospective analysis (ERPs), or (3) false positives from name collisions.

```{r}
#| label: fig-temporal-diff
#| fig-cap: "Year difference distribution for acts with embedded year (blue line = zero difference)"
#| fig-height: 14
#| fig-width: 12
#| column: page

timing_df %>%
  filter(has_name_year) %>%
  ggplot(aes(x = year_diff)) +
  geom_histogram(binwidth = 1, fill = "steelblue", alpha = 0.7) +
  geom_vline(xintercept = 0, color = "blue", linetype = "dashed", linewidth = 0.5) +
  facet_wrap(~label, ncol = 4, scales = "free_y") +
  labs(
    x = "Years from Act Name Year",
    y = "Chunks"
  ) 
  # theme(
  #   strip.text = element_text(size = 7),
  #   axis.text.x = element_text(size = 6),
  #   axis.text.y = element_text(size = 6)
  # )
```

```{r}
#| label: tbl-temporal-summary
#| tbl-cap: "Temporal precision for acts with embedded year"

temporal_summary <- timing_df %>%
  filter(has_name_year) %>%
  group_by(act_name, signed_year) %>%
  summarize(
    n_chunks = n(),
    median_diff = median(year_diff, na.rm = TRUE),
    pct_within_2 = mean(abs(year_diff) <= 2, na.rm = TRUE),
    pct_within_5 = mean(abs(year_diff) <= 5, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(pct_within_2)

temporal_summary %>%
  gt() %>%
  cols_label(
    act_name = "Act Name",
    signed_year = "Year",
    n_chunks = "Chunks",
    median_diff = "Median Δ",
    pct_within_2 = "±2yr",
    pct_within_5 = "±5yr"
  ) %>%
  fmt_number(columns = c(n_chunks, median_diff), decimals = 0) %>%
  fmt_percent(columns = c(pct_within_2, pct_within_5), decimals = 1) %>%
  tab_style(
    style = cell_fill(color = "#ccffcc"),
    locations = cells_body(columns = pct_within_2, rows = pct_within_2 >= 0.5)
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffffcc"),
    locations = cells_body(columns = pct_within_2, rows = pct_within_2 >= 0.25 & pct_within_2 < 0.5)
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffcccc"),
    locations = cells_body(columns = pct_within_2, rows = pct_within_2 < 0.25)
  ) %>%
  gt_theme_report()
```

Acts with low temporal precision (red rows, <25% within ±2 years) likely suffer from name collisions or retrospective discussions dominating contemporaneous mentions. These require manual inspection to assess whether Tier 2 matches contain genuine positive examples.

## Tier Overlap

```{r}
#| label: tier-overlap-check

overlap <- inner_join(
  c1_chunk_data$tier1 %>% select(doc_id, chunk_id),
  c1_chunk_data$tier2 %>% select(doc_id, chunk_id),
  by = c("doc_id", "chunk_id")
)

overlap_status <- if_else(nrow(overlap) == 0, "PASS", paste0("FAIL - ", nrow(overlap), " overlapping chunks"))
```

**Tier Overlap Test**: `r overlap_status`

Tier 1 and Tier 2 should be mutually exclusive by construction. Any overlap indicates a logic error in `identify_chunk_tiers()`. `r if(nrow(overlap) > 0) paste0("Overlapping chunks detected: ", nrow(overlap), " instances.") else "No overlap detected."`

## Token Distribution by Tier

```{r}
#| label: fig-token-distribution
#| fig-cap: "Chunk token distribution across tiers"
#| fig-width: 10
#| fig-height: 6

neg_sample_tokens <- c1_chunk_data$negatives %>%
  slice_sample(n = min(500, nrow(c1_chunk_data$negatives))) %>%
  select(approx_tokens) %>%
  mutate(tier = "Negative (sample)")

token_data <- bind_rows(
  c1_chunk_data$tier1 %>% select(approx_tokens) %>% mutate(tier = "Tier 1"),
  c1_chunk_data$tier2 %>% select(approx_tokens) %>% mutate(tier = "Tier 2"),
  neg_sample_tokens
)

ggplot(token_data, aes(x = approx_tokens, fill = tier)) +
  geom_histogram(bins = 40, alpha = 0.6, position = "identity") +
  scale_fill_manual(values = c("Tier 1" = "#4CAF50", "Tier 2" = "#2196F3", "Negative (sample)" = "#9E9E9E")) +
  labs(
    x = "Approximate Tokens",
    y = "Count",
    fill = "Tier"
  )
```

Token distributions should be similar across tiers. Systematic differences would indicate selection bias (e.g., if Tier 1 only matches short documents). The negative sample should mirror positive tiers in distribution shape.

## Key Density Distribution

The *key density* is a measure of how hard it is to correctly classify a negative chunk as positive. The key desnity measueres the density of appearances of any matcing keyword related to fiscal policy discussion over the total works in each chunk. Hence, a policy-heavy chunk should have a higher density key score. The keys considered were:

```{r}
tar_read(relevance_keys)
```

Again, because this step can only be performed for the US, we won't need to have a similar dictionary in other languages. 


```{r}
#| label: fig-density-histogram
#| fig-cap: "Key density distribution in negative pool"
#| fig-width: 10
#| fig-height: 5

ggplot(c1_chunk_data$negatives, aes(x = key_density)) +
  geom_histogram(bins = 50, fill = "steelblue", alpha = 0.7) +
  labs(
    x = "Key Density (relevance keys per word)",
    y = "Chunks"
  )
```

```{r}
#| label: tbl-density-summary
#| tbl-cap: "Key density bin distribution in negative pool"

c1_chunk_data$negative_density_summary %>%
  gt() %>%
  cols_label(
    density_bin = "Density Range",
    n = "Chunks",
    pct = "Percentage"
  ) %>%
  fmt_number(columns = n, decimals = 0) %>%
  fmt_number(columns = pct, decimals = 1, pattern = "{x}%") %>%
  gt_theme_report()
```

The negative pool exhibits continuous `key_density` variation, enabling stratified precision analysis in S3. High-density negatives contain substantial fiscal vocabulary but lack explicit act mentions, providing challenging test cases where the model must distinguish general fiscal discussion from specific measure descriptions.

## Negative Quality Check

```{r}
#| label: negative-contamination-check

contamination_rate <- diagnostics$contamination_rate
n_contaminated <- diagnostics$n_contaminated
```

**Contamination Rate**: `r scales::percent(contamination_rate, accuracy = 0.01)` (`r scales::comma(n_contaminated)` / `r scales::comma(diagnostics$n_negatives)` chunks)

```{r}
#| label: tbl-contamination-examples
#| tbl-cap: "Example contaminated negative chunks"

if (n_contaminated > 0) {
  diagnostics$contamination_examples %>%
    gt() %>%
    cols_label(
      chunk_id = "Chunk",
      doc_id = "Doc",
      year = "Year",
      text_excerpt = "Text Excerpt"
    ) %>%
    gt_theme_report()
} else {
  tibble(status = "No contaminated chunks detected") %>%
    gt() %>%
    gt_theme_report()
}
```

```{r}
#| label: tbl-negative-sources
#| tbl-cap: "Source type distribution in negative pool"

c1_chunk_data$negatives %>%
  count(source_type, name = "n_chunks") %>%
  mutate(pct = n_chunks / sum(n_chunks) * 100) %>%
  arrange(desc(n_chunks)) %>%
  gt() %>%
  cols_label(
    source_type = "Source Type",
    n_chunks = "Chunks",
    pct = "Percentage"
  ) %>%
  fmt_number(columns = n_chunks, decimals = 0) %>%
  fmt_number(columns = pct, decimals = 1, pattern = "{x}%") %>%
  gt_theme_report()
```

Low contamination rates (<1%) are acceptable, as these chunks likely discuss acts tangentially without containing identifiable passages. Source type balance ensures negatives represent the full document corpus, not biased subsets.

## Summary and Conclusions

```{r}
#| label: tbl-verification-dashboard
#| tbl-cap: "Verification dashboard for chunk tier system"

verification_results <- tibble(
  check = c(
    "Coverage (all acts matched)",
    "Tier overlap (zero expected)",
    "Temporal consistency (>50% acts within ±2yr)",
    "Negative contamination (<1%)",
    "Token distribution (similar across tiers)"
  ),
  result = c(
    paste0(sum(coverage$has_any), " / 44 acts"),
    paste0(nrow(overlap), " overlapping chunks"),
    paste0(sum(temporal_summary$pct_within_2 >= 0.5, na.rm = TRUE), " / ", nrow(temporal_summary), " acts"),
    scales::percent(contamination_rate, accuracy = 0.01),
    "Visual inspection"
  ),
  status = c(
    if_else(n_uncovered == 0, "PASS", "FAIL"),
    if_else(nrow(overlap) == 0, "PASS", "FAIL"),
    if_else(mean(temporal_summary$pct_within_2 >= 0.5, na.rm = TRUE) >= 0.5, "PASS", "WARN"),
    if_else(contamination_rate < 0.01, "PASS", "WARN"),
    "PASS"
  )
)

verification_results %>%
  gt() %>%
  cols_label(
    check = "Verification Check",
    result = "Result",
    status = "Status"
  ) %>%
  tab_style(
    style = cell_fill(color = "#ccffcc"),
    locations = cells_body(columns = status, rows = status == "PASS")
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffffcc"),
    locations = cells_body(columns = status, rows = status == "WARN")
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffcccc"),
    locations = cells_body(columns = status, rows = status == "FAIL")
  ) %>%
  gt_theme_report()
```

### Interpretation

The chunk tier system provides a validated foundation for C1 (Measure ID) codebook evaluation. Key findings:

- **Positive identification** achieved for `r sum(coverage$has_any)` / 44 acts through verbatim passage matches (Tier 1) and act name matching (Tier 2)
- **Matching mechanisms** show redundancy across full name, year-only, and co-occurrence strategies, improving recall
- **Temporal consistency** varies by act, with `r scales::percent(mean(temporal_summary$pct_within_2 >= 0.5, na.rm = TRUE), accuracy = 1)` of acts showing ≥50% matches within ±2 years of signing
- **Negative pool** spans `r scales::comma(nrow(c1_chunk_data$negatives))` chunks with continuous key density distribution, enabling stratified hard-negative sampling
- **Minimal contamination** (`r scales::percent(contamination_rate, accuracy = 0.01)`) in negative pool confirms tier separation

Acts with WARN or FAIL status require manual inspection before use in LOOCV evaluation. See `identifying_known_acts.qmd` for the design rationale and `c1_measure_id.qmd` for Stage 2 evaluation using these tiers.

### Next Steps

1. Investigate uncovered acts (if any) and assess whether missing coverage reflects data gaps or matching logic failures
2. Manually review contaminated negative chunks to determine if they represent true negatives or mislabeled positives
3. Use temporal consistency results to inform few-shot example selection (prioritize acts with high ±2yr precision)
4. Proceed to Stage 2 (Zero-Shot Evaluation) using validated tier assignments for LOOCV
